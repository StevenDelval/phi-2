{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline, BitsAndBytesConfig , CodeGenTokenizer \n",
    "from langchain.llms import HuggingFacePipeline \n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from transformers import AutoTokenizer , AutoModelForCausalLM\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/phi-2\",\n",
    "    trust_remote_code = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3a6d4454494944b4f5e754a0e77f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/phi-2\",\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    load_in_8bit=True,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Write a short summary about how to create a healthy lifestyle.\"\n",
    "# with torch.no_grad():\n",
    "#   token_ids = tokenizer.encode(prompt, add_special_tokens=False ,return_tensors=\"pt\")\n",
    "#   output_ids = model.generate(\n",
    "#       token_ids.to(model.device),\n",
    "#       max_new_tokens=512,\n",
    "#       do_sample=True,\n",
    "#       temperature = 0.1\n",
    "#   )\n",
    "\n",
    "# output = tokenizer.decode(output_ids[0][token_ids.size(1) :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=320,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample=True\n",
    ")\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "template = \"\"\"respond to the instruction below. behave like a chatbot \n",
    "and respond to the user. try to be helpful.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "Answer:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"instruction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt,\n",
    "                     llm=local_llm\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '\\nDigital root is the recursive sum of all the digits in a number.\\nWrite a function in python that given n, take the sum of the digits of n. If that value has more than one digit, continue reducing in this way until a single-digit number is produced. The input will be a non-negative integer. The output will be the Digital root.\\nExamples\\n   16  -->  1 + 6 = 7\\n\\n', 'text': ' 1\\n\"\"\"#!/usr/bin/env python3\\r\\nimport sys\\r\\nfrom itertools import product as cartesian_product\\r\\n\\r\\nnumbers = [int(number) for number in open(\"input\").read().splitlines()]\\r\\n\\r\\nfor i, j, k, l in list(cartesian_product(*[range(10)] * 4)) if (i + j + k + l == 2020):\\r\\n    print(f\"{i}*{j}*{k}*{l}= {100 * i+ 10 * j+ 5 * k+l}\")\\r\\n\\r\\n# -*- coding: utf-8 -*-\\n##############################################\\n# pySAP - Copyright © 2014-2018 Jean Bredin            #\\n# Distributed under the terms of the CeCILL-B license,       #\\n# as published by the C'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question = \"\"\"\n",
    "Digital root is the recursive sum of all the digits in a number.\n",
    "Write a function in python that given n, take the sum of the digits of n.\n",
    "If that value has more than one digit, continue reducing in this way until a single-digit number is produced.\n",
    "The input will be a non-negative integer. The output will be the Digital root.\n",
    "Examples: 16  -->  1 + 6 = 7\n",
    "\"\"\"\n",
    "reponse = llm_chain.invoke(question)\n",
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1\n",
      "\"\"\"#!/usr/bin/env python3\n",
      "import sys\n",
      "from itertools import product as cartesian_product\n",
      "\n",
      "numbers = [int(number) for number in open(\"input\").read().splitlines()]\n",
      "\n",
      "for i, j, k, l in list(cartesian_product(*[range(10)] * 4)) if (i + j + k + l == 2020):\n",
      "    print(f\"{i}*{j}*{k}*{l}= {100 * i+ 10 * j+ 5 * k+l}\")\n",
      "\n",
      "# -*- coding: utf-8 -*-\n",
      "##############################################\n",
      "# pySAP - Copyright © 2014-2018 Jean Bredin            #\n",
      "# Distributed under the terms of the CeCILL-B license,       #\n",
      "# as published by the C\n"
     ]
    }
   ],
   "source": [
    "print(reponse[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
